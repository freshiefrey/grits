{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Window.ipyb\n",
    "\n",
    "This notebook performs a trailing window on specified time series data with the following parameters:\n",
    "- window size\n",
    "- hops\n",
    "In our context, our data is collected on an average of 1 second per movement. Thus, setting our window\n",
    " frame as 1s, with a sampling rate of 50Hz would result in 50 samples per window.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import xarray\n",
    "from tqdm import tqdm\n",
    "\n",
    "def count_samples(window_size, overlaps, sample_size):\n",
    "    if overlaps == 0:\n",
    "        data_size = 1 + (sample_size - window_size)// (window_size - overlaps)\n",
    "    else:\n",
    "        data_size = 1 + (sample_size - window_size)// (window_size - overlaps)\n",
    "    return data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5456\n10911\n2728\n3637\n5455\n"
     ]
    }
   ],
   "source": [
    "print(count_samples(50,0,272800))\n",
    "print(count_samples(50,25,272800))\n",
    "print(count_samples(100,0,272800))\n",
    "print(count_samples(100,25,272800))\n",
    "print(count_samples(100,50,272800))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5455\n"
     ]
    }
   ],
   "source": [
    "##change sampling parameters here\n",
    "total_samples = 3100*22*4\n",
    "window = 100\n",
    "overlap = 50\n",
    "num_gestures = 4\n",
    "data_size = count_samples(window,overlap,total_samples) # per gesture class\n",
    "print(data_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 2006.36it/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create folders if it doesn't exist\n",
    "'''\n",
    "import os\n",
    "location = 'ready_data/window-'+str(window)+'-'+str(overlap)\n",
    "folder = ['ready_data', location]\n",
    "\n",
    "for path in tqdm(folder):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "source": [
    "# PART 1: Processing and saving data into 1 file\n",
    "## Skip to PART 2 if you have ready_data/numpy-window.txt and window & overlap are unchanged"
   ],
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]start!\n",
      " 25%|██▌       | 1/4 [00:00<00:00,  4.83it/s](5455, 100, 6)\n",
      " 50%|█████     | 2/4 [00:00<00:00,  4.84it/s]\n",
      " 75%|███████▌  | 3/4 [00:00<00:00,  4.75it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.67it/s](5455, 100, 6)\n",
      "ok!\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[-1.7500e+00,  1.9000e-01, -3.3000e-01,  2.2770e+01,\n",
       "          2.4999e+02,  2.4999e+02],\n",
       "        [-1.6500e+00, -1.0000e-02, -1.1000e-01,  9.0100e+01,\n",
       "          2.4999e+02,  2.4552e+02],\n",
       "        [-1.3400e+00,  4.0000e-02,  1.3000e-01,  1.2638e+02,\n",
       "          2.4999e+02,  2.2218e+02],\n",
       "        ...,\n",
       "        [-1.6400e+00,  1.7400e+00, -2.0000e+00, -1.2742e+02,\n",
       "         -2.5000e+02, -1.6490e+02],\n",
       "        [-1.3800e+00,  1.8000e+00, -2.1800e+00, -7.3120e+01,\n",
       "         -2.5000e+02, -1.3055e+02],\n",
       "        [-1.1600e+00,  2.1400e+00, -2.2200e+00, -5.4180e+01,\n",
       "         -2.1140e+02, -1.1552e+02]],\n",
       "\n",
       "       [[-1.9400e+00,  2.0700e+00, -2.5700e+00,  3.1700e+00,\n",
       "          2.4999e+02,  1.3746e+02],\n",
       "        [-2.2300e+00,  1.8600e+00, -2.1500e+00, -2.0940e+01,\n",
       "          2.4999e+02,  1.5142e+02],\n",
       "        [-2.5100e+00,  1.6500e+00, -1.9200e+00, -4.0050e+01,\n",
       "          2.4999e+02,  1.6670e+02],\n",
       "        ...,\n",
       "        [-1.3700e+00,  5.8000e-01, -4.2000e-01, -1.6342e+02,\n",
       "         -2.5000e+02, -1.5569e+02],\n",
       "        [-1.5300e+00,  5.7000e-01, -5.9000e-01, -1.5960e+02,\n",
       "         -2.5000e+02, -1.5045e+02],\n",
       "        [-1.7300e+00,  9.0000e-01, -6.7000e-01, -1.7601e+02,\n",
       "         -2.5000e+02, -1.5324e+02]],\n",
       "\n",
       "       [[-8.4000e-01,  2.1700e+00, -2.1200e+00, -5.9910e+01,\n",
       "         -1.4915e+02, -1.0464e+02],\n",
       "        [-8.1000e-01,  2.1500e+00, -2.3600e+00, -4.1780e+01,\n",
       "         -1.5903e+02, -8.1250e+01],\n",
       "        [-6.7000e-01,  2.2900e+00, -2.7400e+00,  5.8000e-01,\n",
       "         -1.5981e+02, -5.1700e+01],\n",
       "        ...,\n",
       "        [-1.1000e-01,  5.0000e-02,  7.5000e-01, -8.9780e+01,\n",
       "         -2.1952e+02, -8.6910e+01],\n",
       "        [-2.2000e-01,  7.0000e-02,  5.6000e-01, -1.0842e+02,\n",
       "         -2.2604e+02, -9.5350e+01],\n",
       "        [-3.7000e-01,  3.0000e-02,  3.6000e-01, -1.1861e+02,\n",
       "         -2.3017e+02, -1.0677e+02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.8000e-01,  9.0000e-01, -3.6000e-01, -1.6900e+00,\n",
       "         -1.9634e+02,  9.5260e+01],\n",
       "        [-3.1000e-01,  8.9000e-01, -3.1000e-01,  2.1640e+01,\n",
       "         -1.9170e+02,  9.3650e+01],\n",
       "        [-3.4000e-01,  9.3000e-01, -2.8000e-01,  3.1810e+01,\n",
       "         -1.9392e+02,  9.4570e+01],\n",
       "        ...,\n",
       "        [-2.6000e-01,  7.6000e-01, -5.6000e-01,  7.8900e+00,\n",
       "          2.4999e+02, -1.1580e+02],\n",
       "        [-3.8000e-01,  7.6000e-01, -6.0000e-01,  1.3630e+01,\n",
       "          2.4999e+02, -1.2620e+02],\n",
       "        [-4.2000e-01,  8.2000e-01, -5.6000e-01,  2.3080e+01,\n",
       "          2.4999e+02, -1.4713e+02]],\n",
       "\n",
       "       [[-4.6000e-01,  1.1400e+00,  2.8000e-01, -2.7650e+01,\n",
       "          3.4670e+01, -2.0680e+01],\n",
       "        [-4.4000e-01,  1.1700e+00,  3.3000e-01, -2.2390e+01,\n",
       "         -4.7100e+00, -2.2400e+00],\n",
       "        [-4.4000e-01,  1.1100e+00,  3.1000e-01, -1.2040e+01,\n",
       "         -4.1020e+01,  1.5900e+01],\n",
       "        ...,\n",
       "        [-9.0000e-02,  6.6000e-01, -1.0100e+00, -5.1000e+00,\n",
       "          6.5140e+01, -3.1180e+01],\n",
       "        [-1.9000e-01,  6.9000e-01, -9.6000e-01, -3.4600e+00,\n",
       "          7.9090e+01, -3.7500e+01],\n",
       "        [-2.0000e-01,  7.1000e-01, -9.7000e-01, -1.4780e+01,\n",
       "          7.8410e+01, -4.0790e+01]],\n",
       "\n",
       "       [[-5.4000e-01,  1.0500e+00, -3.9000e-01,  7.0700e+00,\n",
       "          2.4999e+02, -1.6450e+02],\n",
       "        [-6.4000e-01,  1.1700e+00, -1.3000e-01, -5.1700e+01,\n",
       "          2.4999e+02, -1.4664e+02],\n",
       "        [-4.8000e-01,  9.2000e-01, -2.5000e-01, -6.7090e+01,\n",
       "          2.1218e+02, -1.0918e+02],\n",
       "        ...,\n",
       "        [-2.0000e-01,  7.1000e-01, -8.6000e-01, -6.4000e-01,\n",
       "         -1.8918e+02,  9.7920e+01],\n",
       "        [-2.1000e-01,  6.3000e-01, -8.5000e-01,  3.8100e+00,\n",
       "         -1.5829e+02,  8.2210e+01],\n",
       "        [-2.2000e-01,  5.6000e-01, -8.9000e-01,  2.3550e+01,\n",
       "         -1.3815e+02,  6.4930e+01]]])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sliding window function and params\n",
    "\"\"\"\n",
    "from skimage.util.shape import view_as_windows\n",
    "import warnings\n",
    "\n",
    "csv1 = 'raw_data/combined_buddhaClap.csv'\n",
    "csv2 = 'raw_data/combined_crankLeft.csv'\n",
    "csv3 = 'raw_data/combined_crankRight.csv'\n",
    "csv4 = 'raw_data/combined_knobLeft.csv'\n",
    "csv5 = 'raw_data/combined_knobRight.csv'\n",
    "csv6 = 'raw_data/combined_pushback.csv'\n",
    "csv7 = 'raw_data/combined_swipe.csv'\n",
    "\n",
    "\n",
    "def sliding_window(a, L, overlap=1):\n",
    "    if L==overlap:\n",
    "        raise Exception(\"Overlap arg must be smaller than length of windows\")\n",
    "    S = L - overlap\n",
    "    nd0 = ((len(a)-L)//S)+1\n",
    "    if nd0*S-S!=len(a)-L:\n",
    "        warnings.warn(\"Not all elements were covered\")\n",
    "    output = view_as_windows(a, (L,a.shape[1]), step=S)[:,0,:,:]\n",
    "    print(output.shape)\n",
    "    return output\n",
    "\n",
    "\n",
    "total_array = np.empty((0,window,6))\n",
    "\n",
    "## Select relevant gesture files\n",
    "if num_gestures == 4:\n",
    "    csv_list = [csv1, csv5, csv6, csv7] #4 classes\n",
    "elif num_gestures == 5:\n",
    "    csv_list = [csv1, csv3, csv5, csv6, csv7] # 5 classes\n",
    "elif num_gestures == 7:\n",
    "    csv_list = [csv1, csv2, csv3, csv4, csv5, csv6, csv7] #7 classes\n",
    "\n",
    "print('start!')\n",
    "for csv in tqdm(csv_list):\n",
    "    df = pd.read_csv(csv)\n",
    "    window_array = sliding_window(df.to_numpy(), window, overlap=overlap)\n",
    "    total_array = np.append(total_array, window_array, axis = 0)\n",
    "print('ok!')\n",
    "total_array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "272800"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "len(df.to_numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(21820, 100, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "total_array.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "shape of arr:  (21820, 100, 6)\nshape of load_original_arr:  (21820, 100, 6)\nYes, both the arrays are same\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Save into txt file\n",
    "\"\"\"\n",
    "arr = total_array\n",
    "  \n",
    "# reshaping the array from 3D \n",
    "# matrice to 2D matrice. \n",
    "arr_reshaped = arr.reshape(arr.shape[0], -1) \n",
    "  \n",
    "# saving reshaped array to file. \n",
    "np.savetxt(\"ready_data/numpy-window.txt\", arr_reshaped) \n",
    "  \n",
    "# retrieving data from file. \n",
    "loaded_arr = np.loadtxt(\"ready_data/numpy-window.txt\") \n",
    "  \n",
    "# This loadedArr is a 2D array, therefore \n",
    "# we need to convert it to the original \n",
    "# array shape.reshaping to get original \n",
    "# matrice with original shape. \n",
    "load_original_arr = loaded_arr.reshape( \n",
    "    loaded_arr.shape[0], loaded_arr.shape[1] // arr.shape[2], arr.shape[2]) \n",
    "  \n",
    "# check the shapes: \n",
    "print(\"shape of arr: \", arr.shape) \n",
    "print(\"shape of load_original_arr: \", load_original_arr.shape) \n",
    "  \n",
    "# check if both arrays are same or not: \n",
    "if (load_original_arr == arr).all(): \n",
    "    print(\"Yes, both the arrays are same\") \n",
    "else: \n",
    "    print(\"No, both the arrays are not same\") "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(21820, 600)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "loaded_arr.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "source": [
    "# PART 2: Loading Data and Splitting"
   ],
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nUncomment and Run if you skipped Part 1\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "\"\"\"\n",
    "Uncomment and Run if you skipped Part 1\n",
    "\"\"\"\n",
    "# \"\"\"\n",
    "# Load data contents\n",
    "# \"\"\"\n",
    "# print('start!')\n",
    "# import numpy as np\n",
    "# loaded_arr = np.loadtxt(\"ready_data/numpy-window.txt\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(21820, 600)\n[[-1.7500e+00  1.9000e-01 -3.3000e-01 ... -5.4180e+01 -2.1140e+02\n  -1.1552e+02]\n [-1.9400e+00  2.0700e+00 -2.5700e+00 ... -1.7601e+02 -2.5000e+02\n  -1.5324e+02]]\n"
     ]
    }
   ],
   "source": [
    "x_array = loaded_arr\n",
    "print(x_array.shape)\n",
    "print(x_array[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(21820, 1)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [3],\n",
       "       [3],\n",
       "       [3]])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create gesture class labels according to index\n",
    "0: buddha clap\n",
    "1: crank left\n",
    "2: crank right\n",
    "3: knob left\n",
    "4: knob right\n",
    "5: pushback\n",
    "6: swipe\n",
    "~~~~~~~~~\n",
    "0: buddha clap\n",
    "1: crank right\n",
    "2: knob right\n",
    "3: pushback\n",
    "4: swipe\n",
    "~~~~~~~~~\n",
    "0: buddha clap\n",
    "1: knob right\n",
    "2: pushback\n",
    "3: swipe\n",
    "\"\"\"\n",
    "y_array = np.empty((0,1), int)\n",
    "for i in range(num_gestures):\n",
    "    label_array = np.full((data_size,1), i)\n",
    "    y_array = np.append(y_array, label_array, axis = 0)\n",
    "print(y_array.shape)\n",
    "y_array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 571.45it/s]\n",
      "15272\n",
      "6548\n",
      "15272\n",
      "6548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Split into train-test data\n",
    "\"\"\"\n",
    "train_ratio = 0.7\n",
    "class_size = data_size ## number of samples per class\n",
    "split = round(train_ratio*(class_size)) # Round to nearest integer\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "for i in tqdm(range(num_gestures)):\n",
    "    ##loop through each gesture class index range and split into train-test\n",
    "    train_start = i*(class_size)\n",
    "    train_stop = train_start + split\n",
    "    test_stop = (i+1)*(class_size)\n",
    "\n",
    "    x_train.extend(x_array[train_start:train_stop])\n",
    "    y_train.extend(y_array[train_start:train_stop])\n",
    "    x_test.extend(x_array[train_stop:test_stop])\n",
    "    y_test.extend(y_array[train_stop:test_stop])\n",
    "\n",
    "print()\n",
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\n[array([-5.3000e-01,  3.9000e-01, -3.4000e-01, -7.0370e+01,  1.9668e+02,\n       -2.7700e+00, -5.8000e-01,  4.2000e-01,  1.2000e-01, -2.3020e+01,\n        2.4710e+02,  2.1870e+01, -4.1000e-01,  4.1000e-01,  1.9000e-01,\n        1.1570e+01,  2.4999e+02,  7.9520e+01, -4.6000e-01,  2.4000e-01,\n        2.8000e-01, -1.2222e+02,  2.3036e+02,  8.1380e+01, -1.9000e-01,\n       -3.0000e-02,  6.5000e-01, -1.9043e+02, -1.1010e+01,  8.0960e+01,\n        3.4000e-01, -1.7000e-01,  5.3000e-01, -1.4471e+02,  2.4999e+02,\n        9.1680e+01,  4.5000e-01, -2.0000e-02,  1.0000e+00,  2.4999e+02,\n        1.5325e+02,  6.0960e+01,  6.6000e-01,  5.3000e-01,  1.6000e+00,\n        2.4999e+02,  2.4999e+02,  4.2770e+01, -1.7000e-01,  3.0000e-01,\n        2.3000e+00, -1.6920e+02,  2.4999e+02,  5.8530e+01,  3.5000e-01,\n       -6.0000e-01,  2.6200e+00, -2.3340e+02,  1.1681e+02,  9.3720e+01,\n        9.0000e-01, -1.6600e+00,  4.0000e+00,  1.3821e+02, -2.5000e+02,\n        1.0497e+02, -1.1200e+00, -6.8000e-01,  1.9700e+00, -2.5000e+02,\n        9.4960e+01, -3.4820e+01,  8.4000e-01, -1.8200e+00,  1.0500e+00,\n        1.3348e+02, -2.5000e+02, -2.4460e+01,  2.9000e-01,  4.0000e-02,\n        2.3200e+00,  1.4310e+01, -3.9420e+01, -2.3010e+01,  3.4000e-01,\n       -9.3000e-01,  1.0500e+00, -2.5000e+02, -2.4139e+02, -4.4910e+01,\n        3.1000e-01, -6.3000e-01,  8.0000e-01,  5.6160e+01, -1.9205e+02,\n       -1.0069e+02,  4.7000e-01,  1.1000e-01,  1.1400e+00,  3.4100e+00,\n       -1.6224e+02, -8.5640e+01, -2.1000e-01, -1.8000e-01,  9.1000e-01,\n       -2.0922e+02, -2.2160e+02, -6.5390e+01, -1.9000e-01, -3.8000e-01,\n        3.3000e-01, -1.6134e+02, -2.5000e+02, -7.9220e+01,  1.4000e-01,\n       -1.4000e-01,  7.0000e-02, -3.6160e+01, -1.8248e+02, -1.0713e+02,\n       -2.3000e-01, -5.0000e-02,  2.3000e-01, -9.5350e+01, -1.4315e+02,\n       -1.1577e+02, -4.9000e-01, -6.0000e-02,  2.4000e-01, -1.6290e+02,\n       -1.5634e+02, -1.3512e+02, -4.9000e-01, -9.0000e-02, -3.0000e-02,\n       -1.5181e+02, -2.0247e+02, -1.6051e+02, -5.6000e-01,  1.0000e-01,\n       -1.1000e-01, -2.9940e+01, -1.3297e+02, -1.8943e+02, -8.0000e-01,\n        3.4000e-01, -3.0000e-02,  4.1010e+01, -8.1040e+01, -2.1227e+02,\n       -1.1800e+00,  6.6000e-01, -4.4000e-01,  8.3500e+01, -1.3596e+02,\n       -2.1172e+02, -1.1800e+00,  9.4000e-01, -9.6000e-01,  1.7663e+02,\n       -1.7616e+02, -1.8058e+02, -1.0700e+00,  1.1500e+00, -1.0900e+00,\n        9.8590e+01, -2.5000e+02, -1.3982e+02, -9.7000e-01,  9.6000e-01,\n       -1.6900e+00, -4.4780e+01, -1.8231e+02, -1.1622e+02, -1.1900e+00,\n        1.3500e+00, -1.9200e+00, -3.3380e+01, -2.5000e+02, -1.1008e+02,\n       -5.6000e-01,  1.2700e+00, -2.3300e+00, -2.5000e+02, -2.5000e+02,\n       -8.8420e+01, -1.6000e-01,  8.4000e-01, -3.1900e+00, -8.7040e+01,\n       -1.8015e+02, -8.4790e+01, -1.3000e-01,  1.6600e+00, -3.2400e+00,\n       -7.1060e+01, -2.2138e+02, -1.0413e+02, -2.4000e-01,  1.9500e+00,\n       -3.4500e+00,  1.1230e+02, -7.0570e+01, -4.6710e+01, -7.0000e-02,\n        2.3200e+00, -3.8400e+00, -2.3660e+01, -1.6296e+02,  3.6300e+00,\n        2.9000e-01,  1.7600e+00, -4.0000e+00, -9.2160e+01,  3.9120e+01,\n       -8.7400e+00, -4.5000e-01,  1.7300e+00, -3.6000e+00,  8.3970e+01,\n        1.2003e+02,  3.2300e+00, -4.3000e-01,  1.8300e+00, -3.5400e+00,\n        8.9160e+01,  1.0722e+02,  4.0530e+01, -5.0000e-01,  1.6500e+00,\n       -3.2300e+00,  1.2780e+01,  1.4998e+02,  5.0960e+01, -5.9000e-01,\n        1.3400e+00, -2.8600e+00,  3.2360e+01,  2.4999e+02,  3.7180e+01,\n       -1.1400e+00,  1.2500e+00, -2.3000e+00,  1.4413e+02,  2.4999e+02,\n        3.9850e+01, -1.3000e+00,  1.2300e+00, -1.9300e+00,  1.9358e+02,\n        2.4999e+02,  7.1180e+01, -1.1300e+00,  1.2000e+00, -1.6600e+00,\n        1.3197e+02,  2.4999e+02,  7.7750e+01, -1.1200e+00,  8.9000e-01,\n       -1.5100e+00,  6.2280e+01,  2.4999e+02,  5.9560e+01, -1.1800e+00,\n        7.6000e-01, -1.1800e+00,  9.8080e+01,  2.4999e+02,  5.1610e+01,\n       -1.2600e+00,  6.9000e-01, -7.9000e-01,  9.5700e+01,  2.4999e+02,\n        5.1950e+01, -8.8000e-01,  4.4000e-01, -6.8000e-01,  6.7960e+01,\n        2.1857e+02,  8.6250e+01, -8.5000e-01,  4.1000e-01, -3.9000e-01,\n        1.7750e+01,  2.4999e+02,  6.1970e+01, -7.4000e-01,  2.9000e-01,\n       -2.6000e-01, -5.0390e+01,  2.4999e+02,  5.4540e+01, -6.8000e-01,\n        3.3000e-01, -9.0000e-02,  1.8100e+00,  2.4999e+02,  6.5960e+01,\n       -7.3000e-01,  3.3000e-01,  1.8000e-01, -2.3380e+01,  2.4999e+02,\n        7.8930e+01, -5.7000e-01,  5.0000e-02,  3.0000e-01, -8.9550e+01,\n        1.8013e+02,  1.0487e+02, -4.1000e-01, -1.4000e-01,  5.1000e-01,\n       -1.0596e+02,  9.8450e+01,  9.9220e+01,  1.3000e-01, -2.1000e-01,\n        8.4000e-01, -6.8480e+01,  1.2749e+02,  8.2980e+01, -2.7000e-01,\n       -1.4000e-01,  8.6000e-01,  2.4999e+02,  2.4607e+02,  5.2930e+01,\n        3.7000e-01,  4.5000e-01,  1.4700e+00,  2.4999e+02,  2.4999e+02,\n        3.3070e+01, -1.1000e-01,  3.6000e-01,  2.3500e+00, -1.8182e+02,\n        2.4999e+02,  5.9080e+01, -4.0000e+00, -1.6300e+00,  4.0000e+00,\n       -2.5000e+02,  2.4999e+02, -7.0020e+01,  4.0000e+00, -2.5600e+00,\n       -4.0000e+00,  1.3516e+02, -2.5000e+02,  1.7750e+02, -1.2000e-01,\n        4.7000e-01,  1.1300e+00,  2.4999e+02,  2.4999e+02,  5.7100e+00,\n       -1.5600e+00, -5.6000e-01,  2.1100e+00, -2.5000e+02, -2.5000e+02,\n       -8.5930e+01,  1.9100e+00, -2.0200e+00, -4.6000e-01,  1.0904e+02,\n       -1.8851e+02, -3.9960e+01, -3.0000e-01, -1.0000e-02,  3.0200e+00,\n        2.0070e+02,  9.9200e+00, -3.7490e+01,  8.1000e-01, -2.0000e-01,\n        1.3500e+00, -2.5000e+02, -2.1123e+02, -6.1610e+01,  4.4000e-01,\n       -7.1000e-01,  7.1000e-01, -7.7470e+01, -1.1909e+02, -1.0033e+02,\n        1.4000e-01,  0.0000e+00,  1.5200e+00, -5.5840e+01, -1.1185e+02,\n       -8.4570e+01,  5.0000e-02, -2.1000e-01,  9.4000e-01, -1.8235e+02,\n       -2.2887e+02, -8.1470e+01,  6.0000e-02, -2.5000e-01,  6.3000e-01,\n       -1.1619e+02, -2.4577e+02, -9.2220e+01,  1.0000e-01, -2.8000e-01,\n        4.2000e-01, -1.0387e+02, -2.1526e+02, -1.0352e+02, -8.0000e-02,\n       -2.0000e-01,  3.5000e-01, -3.2040e+01, -1.9086e+02, -1.2335e+02,\n       -1.6000e-01,  2.0000e-02,  3.8000e-01, -4.7300e+01, -2.0459e+02,\n       -1.3355e+02, -2.3000e-01,  1.2000e-01,  2.8000e-01, -9.4700e+01,\n       -2.1104e+02, -1.3733e+02, -3.5000e-01,  1.4000e-01,  1.8000e-01,\n       -1.0264e+02, -1.9528e+02, -1.5173e+02, -5.5000e-01,  1.7000e-01,\n        1.0000e-01, -5.4680e+01, -1.7123e+02, -1.7413e+02, -9.9000e-01,\n        7.5000e-01, -9.0000e-02,  1.0546e+02, -1.4681e+02, -1.9543e+02,\n       -1.2100e+00,  9.0000e-01, -3.0000e-01,  4.2660e+01, -1.8375e+02,\n       -1.8199e+02, -1.2000e+00,  1.0200e+00, -1.1000e+00,  1.3371e+02,\n       -2.5000e+02, -1.3718e+02, -1.1300e+00,  1.2400e+00, -1.3700e+00,\n        1.5393e+02, -2.5000e+02, -8.4450e+01, -8.9000e-01,  1.5600e+00,\n       -1.8700e+00,  1.9180e+01, -2.5000e+02, -4.7260e+01, -1.2200e+00,\n        1.5900e+00, -1.9600e+00, -2.5000e+02, -2.1841e+02, -5.5710e+01,\n       -9.5000e-01,  8.7000e-01, -2.7700e+00, -2.5000e+02, -2.5000e+02,\n       -6.8500e+01, -1.2000e-01,  1.0000e+00, -3.3600e+00,  6.4830e+01,\n       -2.4088e+02, -4.7250e+01, -8.3000e-01,  1.8300e+00, -2.7200e+00,\n       -1.9240e+01, -9.2220e+01, -5.3180e+01, -1.2000e-01,  1.2900e+00,\n       -3.8800e+00, -2.0532e+02, -2.5000e+02, -5.5710e+01, -1.8000e-01,\n        1.6800e+00, -3.6500e+00,  1.4282e+02,  2.9940e+01, -2.5180e+01,\n       -3.0000e-02,  1.7100e+00, -3.8800e+00, -9.6590e+01, -7.2090e+01,\n        1.7160e+01, -3.2000e-01,  1.3600e+00, -3.5100e+00,  7.1700e+00,\n        7.9870e+01,  1.8220e+01, -4.5000e-01,  1.2300e+00, -3.3800e+00,\n        8.1520e+01,  9.6360e+01,  2.3310e+01, -5.8000e-01,  1.4200e+00,\n       -2.9000e+00,  1.1054e+02,  1.7191e+02,  1.7160e+01, -9.3000e-01,\n        1.2700e+00, -2.2300e+00,  9.2080e+01,  2.4629e+02,  3.3200e+00,\n       -9.0000e-01,  1.3300e+00, -1.9800e+00,  1.6946e+02,  2.3409e+02,\n        1.2700e+01, -1.1300e+00,  1.4500e+00, -1.7700e+00,  2.1475e+02,\n        2.4999e+02,  2.3280e+01, -1.1500e+00,  1.4100e+00, -1.3500e+00,\n        1.1878e+02,  2.4999e+02,  4.4870e+01, -1.0200e+00,  9.8000e-01,\n       -1.1200e+00, -1.2340e+01,  2.3764e+02,  5.1560e+01, -1.0100e+00,\n        5.7000e-01, -1.1500e+00,  4.5630e+01,  2.4999e+02,  5.4490e+01,\n       -1.0600e+00,  7.7000e-01, -7.6000e-01,  2.0000e+02,  2.4999e+02,\n        5.5670e+01, -7.7000e-01,  7.2000e-01, -6.0000e-01,  4.4940e+01,\n        2.4999e+02,  3.7100e+01, -6.4000e-01,  4.6000e-01, -3.4000e-01,\n       -2.4830e+01,  2.4999e+02,  3.5670e+01, -1.0100e+00,  3.7000e-01,\n        1.7000e-01, -8.1000e+01,  2.4999e+02,  4.4940e+01, -5.5000e-01,\n        2.8000e-01, -2.0000e-01,  2.1540e+01,  2.2788e+02,  5.3610e+01]), array([-7.3000e-01,  3.3000e-01,  1.8000e-01, -2.3380e+01,  2.4999e+02,\n        7.8930e+01, -5.7000e-01,  5.0000e-02,  3.0000e-01, -8.9550e+01,\n        1.8013e+02,  1.0487e+02, -4.1000e-01, -1.4000e-01,  5.1000e-01,\n       -1.0596e+02,  9.8450e+01,  9.9220e+01,  1.3000e-01, -2.1000e-01,\n        8.4000e-01, -6.8480e+01,  1.2749e+02,  8.2980e+01, -2.7000e-01,\n       -1.4000e-01,  8.6000e-01,  2.4999e+02,  2.4607e+02,  5.2930e+01,\n        3.7000e-01,  4.5000e-01,  1.4700e+00,  2.4999e+02,  2.4999e+02,\n        3.3070e+01, -1.1000e-01,  3.6000e-01,  2.3500e+00, -1.8182e+02,\n        2.4999e+02,  5.9080e+01, -4.0000e+00, -1.6300e+00,  4.0000e+00,\n       -2.5000e+02,  2.4999e+02, -7.0020e+01,  4.0000e+00, -2.5600e+00,\n       -4.0000e+00,  1.3516e+02, -2.5000e+02,  1.7750e+02, -1.2000e-01,\n        4.7000e-01,  1.1300e+00,  2.4999e+02,  2.4999e+02,  5.7100e+00,\n       -1.5600e+00, -5.6000e-01,  2.1100e+00, -2.5000e+02, -2.5000e+02,\n       -8.5930e+01,  1.9100e+00, -2.0200e+00, -4.6000e-01,  1.0904e+02,\n       -1.8851e+02, -3.9960e+01, -3.0000e-01, -1.0000e-02,  3.0200e+00,\n        2.0070e+02,  9.9200e+00, -3.7490e+01,  8.1000e-01, -2.0000e-01,\n        1.3500e+00, -2.5000e+02, -2.1123e+02, -6.1610e+01,  4.4000e-01,\n       -7.1000e-01,  7.1000e-01, -7.7470e+01, -1.1909e+02, -1.0033e+02,\n        1.4000e-01,  0.0000e+00,  1.5200e+00, -5.5840e+01, -1.1185e+02,\n       -8.4570e+01,  5.0000e-02, -2.1000e-01,  9.4000e-01, -1.8235e+02,\n       -2.2887e+02, -8.1470e+01,  6.0000e-02, -2.5000e-01,  6.3000e-01,\n       -1.1619e+02, -2.4577e+02, -9.2220e+01,  1.0000e-01, -2.8000e-01,\n        4.2000e-01, -1.0387e+02, -2.1526e+02, -1.0352e+02, -8.0000e-02,\n       -2.0000e-01,  3.5000e-01, -3.2040e+01, -1.9086e+02, -1.2335e+02,\n       -1.6000e-01,  2.0000e-02,  3.8000e-01, -4.7300e+01, -2.0459e+02,\n       -1.3355e+02, -2.3000e-01,  1.2000e-01,  2.8000e-01, -9.4700e+01,\n       -2.1104e+02, -1.3733e+02, -3.5000e-01,  1.4000e-01,  1.8000e-01,\n       -1.0264e+02, -1.9528e+02, -1.5173e+02, -5.5000e-01,  1.7000e-01,\n        1.0000e-01, -5.4680e+01, -1.7123e+02, -1.7413e+02, -9.9000e-01,\n        7.5000e-01, -9.0000e-02,  1.0546e+02, -1.4681e+02, -1.9543e+02,\n       -1.2100e+00,  9.0000e-01, -3.0000e-01,  4.2660e+01, -1.8375e+02,\n       -1.8199e+02, -1.2000e+00,  1.0200e+00, -1.1000e+00,  1.3371e+02,\n       -2.5000e+02, -1.3718e+02, -1.1300e+00,  1.2400e+00, -1.3700e+00,\n        1.5393e+02, -2.5000e+02, -8.4450e+01, -8.9000e-01,  1.5600e+00,\n       -1.8700e+00,  1.9180e+01, -2.5000e+02, -4.7260e+01, -1.2200e+00,\n        1.5900e+00, -1.9600e+00, -2.5000e+02, -2.1841e+02, -5.5710e+01,\n       -9.5000e-01,  8.7000e-01, -2.7700e+00, -2.5000e+02, -2.5000e+02,\n       -6.8500e+01, -1.2000e-01,  1.0000e+00, -3.3600e+00,  6.4830e+01,\n       -2.4088e+02, -4.7250e+01, -8.3000e-01,  1.8300e+00, -2.7200e+00,\n       -1.9240e+01, -9.2220e+01, -5.3180e+01, -1.2000e-01,  1.2900e+00,\n       -3.8800e+00, -2.0532e+02, -2.5000e+02, -5.5710e+01, -1.8000e-01,\n        1.6800e+00, -3.6500e+00,  1.4282e+02,  2.9940e+01, -2.5180e+01,\n       -3.0000e-02,  1.7100e+00, -3.8800e+00, -9.6590e+01, -7.2090e+01,\n        1.7160e+01, -3.2000e-01,  1.3600e+00, -3.5100e+00,  7.1700e+00,\n        7.9870e+01,  1.8220e+01, -4.5000e-01,  1.2300e+00, -3.3800e+00,\n        8.1520e+01,  9.6360e+01,  2.3310e+01, -5.8000e-01,  1.4200e+00,\n       -2.9000e+00,  1.1054e+02,  1.7191e+02,  1.7160e+01, -9.3000e-01,\n        1.2700e+00, -2.2300e+00,  9.2080e+01,  2.4629e+02,  3.3200e+00,\n       -9.0000e-01,  1.3300e+00, -1.9800e+00,  1.6946e+02,  2.3409e+02,\n        1.2700e+01, -1.1300e+00,  1.4500e+00, -1.7700e+00,  2.1475e+02,\n        2.4999e+02,  2.3280e+01, -1.1500e+00,  1.4100e+00, -1.3500e+00,\n        1.1878e+02,  2.4999e+02,  4.4870e+01, -1.0200e+00,  9.8000e-01,\n       -1.1200e+00, -1.2340e+01,  2.3764e+02,  5.1560e+01, -1.0100e+00,\n        5.7000e-01, -1.1500e+00,  4.5630e+01,  2.4999e+02,  5.4490e+01,\n       -1.0600e+00,  7.7000e-01, -7.6000e-01,  2.0000e+02,  2.4999e+02,\n        5.5670e+01, -7.7000e-01,  7.2000e-01, -6.0000e-01,  4.4940e+01,\n        2.4999e+02,  3.7100e+01, -6.4000e-01,  4.6000e-01, -3.4000e-01,\n       -2.4830e+01,  2.4999e+02,  3.5670e+01, -1.0100e+00,  3.7000e-01,\n        1.7000e-01, -8.1000e+01,  2.4999e+02,  4.4940e+01, -5.5000e-01,\n        2.8000e-01, -2.0000e-01,  2.1540e+01,  2.2788e+02,  5.3610e+01,\n       -4.5000e-01,  4.0000e-01,  1.0000e-01,  5.4060e+01,  2.3135e+02,\n        5.9300e+01, -2.8000e-01,  3.0000e-01,  3.0000e-02, -2.0130e+01,\n        2.4552e+02,  7.6190e+01, -3.1000e-01,  2.0000e-01,  3.0000e-01,\n       -3.9930e+01,  2.2290e+02,  8.4980e+01, -3.6000e-01,  1.1000e-01,\n        7.2000e-01, -1.3498e+02,  1.9129e+02,  7.9740e+01, -1.5000e-01,\n       -2.9000e-01,  1.1500e+00, -1.8874e+02,  2.0960e+02,  8.1510e+01,\n        2.5000e-01, -6.0000e-01,  8.4000e-01,  9.9270e+01,  2.0498e+02,\n        7.8060e+01,  3.0000e-01,  1.6000e-01,  1.5900e+00,  2.4999e+02,\n        2.4999e+02,  4.3710e+01,  2.0000e-01,  3.0000e-01,  1.9800e+00,\n        2.3000e+01,  2.1848e+02,  5.9640e+01,  4.4000e-01, -2.9000e-01,\n        1.9300e+00, -7.3030e+01,  1.4421e+02,  7.9690e+01,  8.6000e-01,\n       -3.4000e-01,  2.2900e+00, -9.3200e+00,  1.5995e+02,  7.4890e+01,\n       -8.1000e-01, -2.7800e+00,  4.0000e+00,  7.6100e+00, -7.9050e+01,\n        9.4120e+01,  2.4800e+00,  6.2000e-01,  3.1000e-01,  2.4999e+02,\n       -2.2429e+02,  3.0730e+01,  6.7000e-01,  5.7000e-01,  2.4900e+00,\n       -2.5000e+02,  2.4999e+02, -2.4920e+01, -1.1000e-01, -1.5700e+00,\n        1.3600e+00, -2.5000e+02, -1.0645e+02,  3.1360e+01,  5.5000e-01,\n       -3.8000e-01,  2.3800e+00,  1.7955e+02, -1.7222e+02, -1.2910e+01,\n        7.0000e-01, -4.6000e-01,  1.3900e+00, -2.4185e+02, -1.3444e+02,\n       -2.3570e+01,  3.9000e-01, -4.9000e-01,  1.2500e+00, -1.0040e+02,\n       -1.4931e+02, -5.3570e+01,  1.5000e-01, -3.6000e-01,  1.1000e+00,\n       -7.3510e+01, -1.8497e+02, -7.2300e+01,  3.0000e-01, -8.0000e-02,\n        7.9000e-01, -2.8650e+01, -2.1620e+02, -6.9380e+01,  2.0000e-01,\n       -2.0000e-02,  7.4000e-01, -9.3630e+01, -1.9358e+02, -6.2210e+01,\n       -9.0000e-02, -1.9000e-01,  4.8000e-01, -1.5977e+02, -2.2666e+02,\n       -7.4700e+01, -1.3000e-01, -3.0000e-01,  1.8000e-01, -9.1340e+01,\n       -2.3567e+02, -9.5580e+01, -1.4000e-01, -1.6000e-01,  4.0000e-02,\n       -1.0930e+01, -2.2468e+02, -1.1151e+02, -2.0000e-01,  4.0000e-02,\n        1.3000e-01, -7.6800e+00, -1.7232e+02, -1.2247e+02, -4.1000e-01,\n        1.0000e-01,  2.7000e-01, -7.4400e+01, -1.4440e+02, -1.3294e+02,\n       -8.3000e-01,  6.0000e-02,  1.7000e-01, -7.3760e+01, -1.7457e+02,\n       -1.6891e+02, -1.0000e+00,  2.8000e-01, -1.0000e-02,  5.9810e+01,\n       -1.8074e+02, -1.8821e+02, -1.1900e+00,  7.6000e-01, -5.5000e-01,\n        4.2240e+01, -1.8303e+02, -1.8468e+02, -1.3400e+00,  1.0500e+00,\n       -8.1000e-01,  7.3700e+01, -1.8566e+02, -1.7453e+02, -1.6800e+00,\n        1.4100e+00, -8.9000e-01,  2.0710e+01, -2.0801e+02, -1.2791e+02,\n       -1.1900e+00,  1.1400e+00, -1.3700e+00, -5.9960e+01, -2.5000e+02,\n       -5.8070e+01, -9.3000e-01,  1.1500e+00, -1.9000e+00, -9.8920e+01,\n       -2.5000e+02, -4.1570e+01, -9.4000e-01,  1.3400e+00, -2.3400e+00,\n       -2.1866e+02, -2.1687e+02, -9.1610e+01, -9.1000e-01,  8.4000e-01,\n       -2.1700e+00, -2.4435e+02, -2.0834e+02, -1.3856e+02, -8.6000e-01,\n        1.2900e+00, -2.4700e+00,  1.5339e+02, -1.5796e+02, -6.5270e+01,\n       -7.3000e-01,  1.9900e+00, -2.8500e+00,  1.4970e+01, -2.5000e+02,\n       -2.9270e+01,  1.3000e-01,  1.8100e+00, -3.7800e+00, -2.4268e+02,\n       -2.2988e+02, -7.4320e+01, -6.8000e-01,  2.0400e+00, -3.5800e+00,\n        1.0148e+02,  3.1940e+01, -6.7150e+01, -5.7000e-01,  2.3400e+00,\n       -4.0000e+00,  3.7730e+01, -1.5475e+02,  1.4640e+01,  0.0000e+00,\n        2.0100e+00, -4.0000e+00,  3.1730e+01, -5.5830e+01,  7.0470e+01,\n       -2.2000e-01,  1.6400e+00, -4.0000e+00, -1.4760e+01,  9.8900e+01,\n        4.3370e+01, -5.6000e-01,  1.3600e+00, -3.4400e+00,  4.6810e+01,\n        2.4999e+02,  7.9000e-01, -1.1100e+00,  1.4300e+00, -2.9100e+00,\n        1.4868e+02,  2.4999e+02,  9.6400e+00, -1.2500e+00,  1.6400e+00,\n       -2.3800e+00,  1.7786e+02,  2.4999e+02,  6.0450e+01, -1.1400e+00,\n        1.3200e+00, -2.3500e+00,  1.9140e+01,  2.1210e+02,  7.1350e+01,\n       -1.2500e+00,  9.6000e-01, -2.1500e+00,  6.9050e+01,  2.4999e+02,\n        5.5990e+01, -1.5700e+00,  8.5000e-01, -1.7500e+00,  1.4211e+02,\n        2.4999e+02,  4.1470e+01, -1.6900e+00,  9.7000e-01, -1.4300e+00,\n        2.0387e+02,  2.4999e+02,  5.1780e+01, -1.5500e+00,  9.9000e-01,\n       -1.1600e+00,  1.2823e+02,  2.4999e+02,  4.9550e+01, -1.2500e+00,\n        8.3000e-01, -9.1000e-01,  4.4650e+01,  2.4999e+02,  3.5350e+01])]\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train[0]))\n",
    "print(x_test[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.00it/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Convert Lists into Numpy Arrays\n",
    "'''\n",
    "for _ in tqdm(range(1)):\n",
    "    x_train_arr = np.array(x_train)\n",
    "    y_train_arr = np.array(y_train)\n",
    "    x_test_arr = np.array(x_test)\n",
    "    y_test_arr = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(15272, 600)\n(15272, 1)\n(6548, 600)\n(6548, 1)\n[[-1.7500e+00  1.9000e-01 -3.3000e-01 ... -5.4180e+01 -2.1140e+02\n  -1.1552e+02]\n [-1.9400e+00  2.0700e+00 -2.5700e+00 ... -1.7601e+02 -2.5000e+02\n  -1.5324e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_arr.shape)\n",
    "print(y_train_arr.shape)\n",
    "print(x_test_arr.shape)\n",
    "print(y_test_arr.shape)\n",
    "print(x_train_arr[0:2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1/1 [00:17<00:00, 17.65s/it]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SAVE 2D Matrices into text & numpy\n",
    "\"\"\"\n",
    "for _ in tqdm(range(1)):\n",
    "    # saving reshaped array to file. \n",
    "    np.savetxt(location+'/x_train.txt', x_train_arr)\n",
    "    np.savetxt(location+'/y_train.txt', y_train_arr)\n",
    "    np.savetxt(location+'/x_test.txt', x_test_arr)\n",
    "    np.savetxt(location+'/y_test.txt', y_test_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%arr = total_array\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "114d62b75f995e056581e916f376bfc5abfea1a21c26be0a5cfbbf064ec4142f"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.7-final"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}