{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for GPU/CUDA ML, comment out if you dont have it configured.\n",
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(53466, 50, 6)\n(53466, 7)\n(22904, 50, 6)\n(22904, 7)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "import numpy as np\n",
    "from numpy import dstack\n",
    "import keras.backend as kb\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical, np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# load_dataset:\n",
    "trainxshape = (53466, 50, 6)\n",
    "trainyshape = (53466, 1)\n",
    "testxshape = (22911, 50, 6)\n",
    "testyshape = (22911, 1)\n",
    "\n",
    "## Load data previously saved as numpy text and reshape it to orginal form\n",
    "loaded_arr = np.loadtxt(\"ready_data/x_train.txt\")\n",
    "x_train = loaded_arr.reshape(\n",
    "    loaded_arr.shape[0], loaded_arr.shape[1] // trainxshape[2], trainxshape[2])\n",
    "\n",
    "loaded_arr1 = np.loadtxt(\"ready_data/y_train.txt\")\n",
    "y_train = loaded_arr1\n",
    "\n",
    "loaded_arr2 = np.loadtxt(\"ready_data/x_test.txt\")\n",
    "x_test = loaded_arr2.reshape(loaded_arr2.shape[0], loaded_arr2.shape[1] // testxshape[2], testxshape[2])\n",
    "\n",
    "loaded_arr3 = np.loadtxt(\"ready_data/y_test.txt\")\n",
    "y_test = loaded_arr3\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# encoder = LabelEncoder()\n",
    "# encoder.fit(y_train)\n",
    "# encoded_ytrain = encoder.transform(y_train)\n",
    "# encoded_ytest = encoder.transform(y_test)\n",
    "\n",
    "# ohe_ytrain = np_utils.to_categorical(encoded_ytrain, num_classes=7)\n",
    "# ohe_ytest = np_utils.to_categorical(encoded_ytest, num_classes=7)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# new = to_categorical(encoded_ytrain)\n",
    "# print(new.shape)\n",
    "# print(new[0])\n",
    "\n",
    "print(y_test[0])\n",
    "# print(encoded_ytrain.shape)\n",
    "# print(encoded_ytrain)\n",
    "# print(encoded_ytest.shape)\n",
    "# print(encoded_ytest)\n",
    "# print(ohe_ytrain.shape)\n",
    "# print(ohe_ytrain)\n",
    "# print(ohe_ytest.shape)\n",
    "# print(ohe_ytest[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(x_train, y_train, x_test, y_test, dropout):\n",
    "    print(\"start evaluation!\")\n",
    "    LR = 0.0001\n",
    "    verbose, epochs, batch_size = 1, 10, 64\n",
    "    # timesteps = window size, #n_features = 6, n_outputs =\n",
    "    n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(n_timesteps, n_features), dropout=dropout))\n",
    "    # model.add(LSTM(100, return_sequences=True, input_shape=(n_timesteps, n_features), dropout=dropout))\n",
    "    # model.add(LSTM(10, return_sequences=True))\n",
    "    # model.add(LSTM(64, return_sequences=True))\n",
    "    # model.add(LSTM(32, return_sequences=True))\n",
    "    # model.add(LSTM(100, dropout=dropout))\n",
    "    # model.add(Dropout(0.5))\n",
    "    # model.add(Dense(100, activation='relu'))\n",
    "    # model.add(Dropout(0.3))\n",
    "    # model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    kb.set_value(model.optimizer.learning_rate, LR)\n",
    "    model.summary()\n",
    "\n",
    "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # save model\n",
    "    model.save('lstm_model4')\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=verbose)\n",
    "    return accuracy\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "start evaluation!\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100)               42800     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 707       \n",
      "=================================================================\n",
      "Total params: 43,507\n",
      "Trainable params: 43,507\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "836/836 [==============================] - 5s 6ms/step - loss: 1.5223 - accuracy: 0.4586\n",
      "Epoch 2/10\n",
      "836/836 [==============================] - 5s 6ms/step - loss: 0.8987 - accuracy: 0.7345\n",
      "Epoch 3/10\n",
      "836/836 [==============================] - 5s 6ms/step - loss: 0.4007 - accuracy: 0.9108\n",
      "Epoch 4/10\n",
      "836/836 [==============================] - 5s 6ms/step - loss: 0.1714 - accuracy: 0.9716\n",
      "Epoch 5/10\n",
      "836/836 [==============================] - 5s 6ms/step - loss: 0.0978 - accuracy: 0.9845\n",
      "Epoch 6/10\n",
      "836/836 [==============================] - 5s 6ms/step - loss: 0.0634 - accuracy: 0.9897\n",
      "Epoch 7/10\n",
      "836/836 [==============================] - 6s 7ms/step - loss: 0.0470 - accuracy: 0.9922\n",
      "Epoch 8/10\n",
      "836/836 [==============================] - 5s 6ms/step - loss: 0.0399 - accuracy: 0.9926\n",
      "Epoch 9/10\n",
      "836/836 [==============================] - 5s 6ms/step - loss: 0.0318 - accuracy: 0.9940\n",
      "Epoch 10/10\n",
      "836/836 [==============================] - 5s 6ms/step - loss: 0.0288 - accuracy: 0.9941\n",
      "INFO:tensorflow:Assets written to: lstm_model4\\assets\n",
      "358/358 [==============================] - 1s 4ms/step - loss: 3.9191 - accuracy: 0.6103\n",
      ">#1: 61.029\n",
      "[61.02864146232605]\n",
      "Accuracy: 61.029% (+/-0.000)\n"
     ]
    }
   ],
   "source": [
    "# run an experiment\n",
    "def run_experiment(repeats=1):\n",
    "    dropout = 0.2\n",
    "    # dropout = [0.0, 0.2, 0.3, 0.4, 0.5]\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(x_train, y_train, x_test, y_test, dropout)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r + 1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_results(scores)\n",
    "\n",
    "\n",
    "# run the experiment\n",
    "run_experiment()\n"
   ]
  },
  {
   "source": [
    "## Testing the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from os import listdir\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "from keras.models import load_model\n",
    "\n",
    "MODEL_NAME = 'lstm_model4'\n",
    "\n",
    "# Our samples directory\n",
    "SAMPLE_PATH = './ready_data'\n",
    "\n",
    "# session = tf.compat.v1.Session(graph=tf.compat.v1.Graph())\n",
    "\n",
    "model = load_model(MODEL_NAME)\n",
    "\n",
    "sample_files = listdir(SAMPLE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2.64585076e-04 4.57587748e-06 2.94613510e-05 6.37756693e-06\n 3.49302463e-05 1.39476615e-05 9.99646187e-01]\n[0. 0. 0. 0. 0. 0. 1.]\n[0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "rounded = np.round(y_pred)\n",
    "\n",
    "print(y_pred[0])\n",
    "print(rounded[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_cm(y_true, y_pred, class_names):\n",
    "  cm = confusion_matrix(y_true, y_pred)\n",
    "  fig, ax = plt.subplots(figsize=(18, 16)) \n",
    "  ax = sns.heatmap(\n",
    "      cm, \n",
    "      annot=True, \n",
    "      fmt=\"d\", \n",
    "      cmap=sns.diverging_palette(220, 20, n=7),\n",
    "      ax=ax\n",
    "  )\n",
    "\n",
    "  plt.ylabel('Actual')\n",
    "  plt.xlabel('Predicted')\n",
    "  ax.set_xticklabels(class_names)\n",
    "  ax.set_yticklabels(class_names)\n",
    "  b, t = plt.ylim() # discover the values for bottom and top\n",
    "  b += 0.5 # Add 0.5 to the bottom\n",
    "  t -= 0.5 # Subtract 0.5 from the top\n",
    "  plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "  plt.show() # ta-da!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Buddha clap' 'Crank left' 'Crank right' 'Knob left' 'Knob right'\n 'Pushback' 'Swipe']\n<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"Buddha clap\", \"Crank left\", \"Crank right\", \"Knob left\", \"Knob right\", \"Pushback\", \"Swipe\"]\n",
    "name = np.array(class_names)\n",
    "print(name)\n",
    "print(type(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "enc = enc.fit(name.reshape(-1, 1))\n",
    "# y_pred = enc.transform(y_pred)\n",
    "y_pred = enc.inverse_transform(rounded)\n",
    "y_test_label = enc.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['Swipe']\n ['Swipe']\n ['Swipe']\n ...\n ['Buddha clap']\n ['Buddha clap']\n ['Buddha clap']]\n[['Swipe']\n ['Swipe']\n ['Swipe']\n ...\n ['Buddha clap']\n ['Buddha clap']\n ['Buddha clap']]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(y_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and multilabel-indicator targets",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-9681a3cd5a5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m   \u001b[0my_test_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mrounded\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m   \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32m<ipython-input-52-762d3bb0b9fb>\u001b[0m in \u001b[0;36mplot_cm\u001b[1;34m(y_true, y_pred, class_names)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m   \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m   \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m   ax = sns.heatmap(\n",
      "\u001b[1;32mc:\\Users\\mervi\\Documents\\MEGAsync\\School\\Y3Sem1\\CS3237 Introduction to IoT\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mervi\\Documents\\MEGAsync\\School\\Y3Sem1\\CS3237 Introduction to IoT\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \"\"\"\n\u001b[1;32m--> 276\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mervi\\Documents\\MEGAsync\\School\\Y3Sem1\\CS3237 Introduction to IoT\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 91\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "plot_cm(\n",
    "  y_test_label,\n",
    "  rounded,\n",
    "  name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}