{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    gyrox   gyroy   gyroz   acelx   acely   acelz\n0   -1.75    0.19   -0.33   22.77  249.99  249.99\n1   -1.65   -0.01   -0.11   90.10  249.99  245.52\n2   -1.34    0.04    0.13  126.38  249.99  222.18\n3   -1.06   -0.01    0.26  130.48  249.99  187.18\n4   -0.83   -0.14    0.30  147.04  245.03  161.22\n..    ...     ...     ...     ...     ...     ...\n95  -1.74    1.51   -1.49 -111.26 -250.00 -169.74\n96  -1.85    1.83   -1.81 -152.55 -250.00 -197.15\n97  -1.64    1.74   -2.00 -127.42 -250.00 -164.90\n98  -1.38    1.80   -2.18  -73.12 -250.00 -130.55\n99  -1.16    2.14   -2.22  -54.18 -211.40 -115.52\n\n[100 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gyrox</th>\n      <th>gyroy</th>\n      <th>gyroz</th>\n      <th>acelx</th>\n      <th>acely</th>\n      <th>acelz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.75</td>\n      <td>0.19</td>\n      <td>-0.33</td>\n      <td>22.77</td>\n      <td>249.99</td>\n      <td>249.99</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.65</td>\n      <td>-0.01</td>\n      <td>-0.11</td>\n      <td>90.10</td>\n      <td>249.99</td>\n      <td>245.52</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.34</td>\n      <td>0.04</td>\n      <td>0.13</td>\n      <td>126.38</td>\n      <td>249.99</td>\n      <td>222.18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.06</td>\n      <td>-0.01</td>\n      <td>0.26</td>\n      <td>130.48</td>\n      <td>249.99</td>\n      <td>187.18</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.83</td>\n      <td>-0.14</td>\n      <td>0.30</td>\n      <td>147.04</td>\n      <td>245.03</td>\n      <td>161.22</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>-1.74</td>\n      <td>1.51</td>\n      <td>-1.49</td>\n      <td>-111.26</td>\n      <td>-250.00</td>\n      <td>-169.74</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>-1.85</td>\n      <td>1.83</td>\n      <td>-1.81</td>\n      <td>-152.55</td>\n      <td>-250.00</td>\n      <td>-197.15</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>-1.64</td>\n      <td>1.74</td>\n      <td>-2.00</td>\n      <td>-127.42</td>\n      <td>-250.00</td>\n      <td>-164.90</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>-1.38</td>\n      <td>1.80</td>\n      <td>-2.18</td>\n      <td>-73.12</td>\n      <td>-250.00</td>\n      <td>-130.55</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>-1.16</td>\n      <td>2.14</td>\n      <td>-2.22</td>\n      <td>-54.18</td>\n      <td>-211.40</td>\n      <td>-115.52</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 1
    }
   ],
   "source": [
    "\"\"\"\n",
    "Window.ipyb\n",
    "\n",
    "This notebook performs a trailing window on specified time series data with the following parameters:\n",
    "- window size\n",
    "- hops\n",
    "In our context, our data is collected on an average of 1 second per movement. Thus, setting our window\n",
    " frame as 1s, with a sampling rate of 50Hz would result in 50 samples per window.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import xarray\n",
    "\n",
    "# with open ('training_data/combined_buddhaClap.csv', 'r') as r:\n",
    "csv1 = 'training_data/combined_buddhaClap.csv'\n",
    "csv2 = 'training_data/combined_crankLeft.csv'\n",
    "csv3 = 'training_data/combined_crankRight.csv'\n",
    "csv4 = 'training_data/combined_knobLeft.csv'\n",
    "csv5 = 'training_data/combined_knobRight.csv'\n",
    "csv6= 'training_data/combined_pushback.csv'\n",
    "csv7 = 'training_data/combined_swipe.csv'\n",
    "\n",
    "df = pd.read_csv('training_data/test.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.7500e+00,  1.9000e-01, -3.3000e-01,  2.2770e+01,  2.4999e+02,\n         2.4999e+02],\n       [-1.6500e+00, -1.0000e-02, -1.1000e-01,  9.0100e+01,  2.4999e+02,\n         2.4552e+02],\n       [-1.3400e+00,  4.0000e-02,  1.3000e-01,  1.2638e+02,  2.4999e+02,\n         2.2218e+02],\n       [-1.0600e+00, -1.0000e-02,  2.6000e-01,  1.3048e+02,  2.4999e+02,\n         1.8718e+02],\n       [-8.3000e-01, -1.4000e-01,  3.0000e-01,  1.4704e+02,  2.4503e+02,\n         1.6122e+02],\n       [-6.2000e-01, -2.7000e-01,  3.3000e-01,  1.8921e+02,  2.3178e+02,\n         1.3690e+02],\n       [-5.4000e-01, -1.9000e-01,  4.0000e-01,  2.4999e+02,  2.2418e+02,\n         1.1510e+02],\n       [-2.7000e-01, -2.0000e-02,  6.3000e-01,  2.4999e+02,  2.1301e+02,\n         1.0772e+02],\n       [ 3.0000e-02, -8.0000e-02,  9.9000e-01,  2.4999e+02,  2.1532e+02,\n         1.0066e+02],\n       [ 1.8000e-01,  5.0000e-02,  1.3900e+00,  2.4999e+02,  2.0455e+02,\n         6.7020e+01],\n       [ 1.4000e-01,  5.0000e-01,  1.7300e+00,  2.0731e+02,  1.4995e+02,\n         1.8060e+01],\n       [ 2.9000e-01,  6.0000e-01,  1.8300e+00,  4.7160e+01,  1.0445e+02,\n         6.7800e+00],\n       [ 1.2000e-01,  6.8000e-01,  2.2500e+00, -1.1939e+02,  7.1970e+01,\n         1.7090e+01],\n       [ 2.9100e+00,  1.3400e+00,  2.2600e+00,  1.6950e+02, -7.9580e+01,\n        -3.0830e+01],\n       [ 5.9000e-01,  1.1400e+00,  2.3700e+00, -4.2340e+01, -5.9750e+01,\n        -5.4000e+00],\n       [ 3.6000e-01,  3.5000e-01,  1.4300e+00, -1.2282e+02,  1.4600e+00,\n        -1.3610e+01],\n       [ 3.8000e-01, -4.0000e-02,  1.2200e+00, -8.1540e+01,  1.0760e+01,\n        -2.6020e+01],\n       [ 4.3000e-01, -1.6000e-01,  1.4400e+00, -3.7050e+01, -2.3530e+01,\n        -1.1600e+01],\n       [ 4.2000e-01,  1.9000e-01,  1.7700e+00, -4.3190e+01, -7.7080e+01,\n        -2.4870e+01],\n       [ 4.0000e-01,  2.5000e-01,  1.6100e+00, -1.0431e+02, -1.2842e+02,\n        -2.8920e+01],\n       [ 3.7000e-01,  7.0000e-02,  1.2200e+00, -1.2460e+02, -1.5383e+02,\n        -3.8500e+01],\n       [ 3.2000e-01,  8.0000e-02,  9.8000e-01, -1.0546e+02, -1.7027e+02,\n        -4.9260e+01],\n       [ 2.2000e-01,  1.7000e-01,  8.0000e-01, -9.3400e+01, -1.8330e+02,\n        -5.6300e+01],\n       [ 5.0000e-02,  3.0000e-01,  6.1000e-01, -1.0267e+02, -1.9908e+02,\n        -6.3610e+01],\n       [-1.0000e-01,  3.6000e-01,  4.1000e-01, -1.2946e+02, -2.1130e+02,\n        -7.3030e+01],\n       [-2.3000e-01,  2.5000e-01,  2.4000e-01, -1.3695e+02, -2.0723e+02,\n        -8.3020e+01],\n       [-3.9000e-01,  1.4000e-01,  1.1000e-01, -1.1826e+02, -2.0531e+02,\n        -9.0680e+01],\n       [-5.0000e-01,  8.0000e-02,  5.0000e-02, -8.7340e+01, -2.1457e+02,\n        -9.5150e+01],\n       [-6.2000e-01,  6.0000e-02, -4.0000e-02, -6.5640e+01, -2.2646e+02,\n        -1.0152e+02],\n       [-7.7000e-01,  1.2000e-01, -1.6000e-01, -5.5240e+01, -2.4197e+02,\n        -1.1189e+02],\n       [-9.5000e-01,  1.7000e-01, -3.3000e-01, -5.5890e+01, -2.5000e+02,\n        -1.1520e+02],\n       [-1.1000e+00,  1.7000e-01, -5.0000e-01, -6.3260e+01, -2.5000e+02,\n        -1.1658e+02],\n       [-1.2400e+00,  2.6000e-01, -6.9000e-01, -6.2070e+01, -2.5000e+02,\n        -1.3197e+02],\n       [-1.4200e+00,  3.2000e-01, -8.9000e-01, -4.3550e+01, -2.5000e+02,\n        -1.4906e+02],\n       [-1.6000e+00,  5.1000e-01, -1.0000e+00, -3.7170e+01, -2.5000e+02,\n        -1.5697e+02],\n       [-1.6500e+00,  6.5000e-01, -1.1400e+00, -4.7920e+01, -2.5000e+02,\n        -1.5980e+02],\n       [-1.7700e+00,  8.8000e-01, -1.2700e+00, -6.9790e+01, -2.5000e+02,\n        -1.8091e+02],\n       [-1.8400e+00,  9.5000e-01, -1.5200e+00, -7.8730e+01, -2.5000e+02,\n        -1.8694e+02],\n       [-2.0000e+00,  9.1000e-01, -1.7300e+00, -6.0690e+01, -2.5000e+02,\n        -1.7254e+02],\n       [-1.6500e+00,  1.2800e+00, -1.8700e+00, -5.7190e+01, -2.5000e+02,\n        -1.8187e+02],\n       [-2.0400e+00,  1.2400e+00, -2.3500e+00, -2.7820e+01, -2.5000e+02,\n        -1.9164e+02],\n       [-2.0700e+00,  1.4600e+00, -2.8700e+00,  4.3480e+01, -2.5000e+02,\n        -2.0757e+02],\n       [-1.1000e+00,  1.6700e+00, -3.2500e+00,  3.5580e+01, -2.5000e+02,\n        -1.4690e+02],\n       [-1.0200e+00,  2.1800e+00, -3.7300e+00,  2.2680e+01, -2.2848e+02,\n        -9.1590e+01],\n       [-4.7000e-01,  2.4600e+00, -3.8600e+00, -5.1620e+01, -1.1284e+02,\n        -8.8720e+01],\n       [-4.5000e-01,  2.4800e+00, -3.8800e+00, -7.9340e+01, -1.3290e+01,\n        -7.1230e+01],\n       [-6.5000e-01,  2.6900e+00, -3.7200e+00, -1.0214e+02,  2.0920e+01,\n        -4.5730e+01],\n       [-7.9000e-01,  2.4900e+00, -3.6100e+00, -9.9390e+01,  5.4380e+01,\n         2.3390e+01],\n       [-1.1200e+00,  2.1900e+00, -3.4100e+00, -4.0690e+01,  1.4500e+02,\n         9.3510e+01],\n       [-1.6200e+00,  2.2000e+00, -3.0000e+00,  1.0530e+01,  2.2304e+02,\n         1.2435e+02],\n       [-1.9400e+00,  2.0700e+00, -2.5700e+00,  3.1700e+00,  2.4999e+02,\n         1.3746e+02],\n       [-2.2300e+00,  1.8600e+00, -2.1500e+00, -2.0940e+01,  2.4999e+02,\n         1.5142e+02],\n       [-2.5100e+00,  1.6500e+00, -1.9200e+00, -4.0050e+01,  2.4999e+02,\n         1.6670e+02],\n       [-2.6900e+00,  1.3000e+00, -1.6900e+00, -2.1800e+01,  2.4999e+02,\n         1.9481e+02],\n       [-2.6200e+00,  1.1700e+00, -1.3800e+00,  1.5340e+01,  2.4999e+02,\n         2.1773e+02],\n       [-2.5500e+00,  1.0800e+00, -1.1300e+00,  2.4670e+01,  2.4999e+02,\n         2.2603e+02],\n       [-2.4100e+00,  9.5000e-01, -8.5000e-01,  1.3370e+01,  2.4999e+02,\n         2.2853e+02],\n       [-2.2900e+00,  7.2000e-01, -7.2000e-01, -6.9900e+00,  2.4999e+02,\n         2.2771e+02],\n       [-2.2000e+00,  5.3000e-01, -5.8000e-01, -1.4100e+01,  2.4999e+02,\n         2.2419e+02],\n       [-1.9700e+00,  2.9000e-01, -4.3000e-01, -1.9500e+00,  2.4999e+02,\n         2.2402e+02],\n       [-1.7400e+00,  1.3000e-01, -2.4000e-01,  1.8200e+01,  2.4999e+02,\n         2.2418e+02],\n       [-1.5000e+00,  4.0000e-02, -5.0000e-02,  3.2730e+01,  2.4999e+02,\n         2.1289e+02],\n       [-1.2700e+00, -3.0000e-02,  1.3000e-01,  3.9930e+01,  2.4999e+02,\n         1.9009e+02],\n       [-1.0800e+00, -9.0000e-02,  2.8000e-01,  5.4420e+01,  2.4999e+02,\n         1.6667e+02],\n       [-8.3000e-01, -1.6000e-01,  4.2000e-01,  9.1250e+01,  2.4999e+02,\n         1.4380e+02],\n       [-5.9000e-01, -1.5000e-01,  5.9000e-01,  1.4466e+02,  2.4999e+02,\n         1.2625e+02],\n       [-4.8000e-01, -2.0000e-02,  6.9000e-01,  2.0635e+02,  2.3368e+02,\n         1.1443e+02],\n       [ 1.0000e-02, -1.9000e-01,  9.8000e-01,  2.4305e+02,  2.2559e+02,\n         1.1897e+02],\n       [ 2.3000e-01, -7.0000e-02,  1.4300e+00,  2.4999e+02,  2.4999e+02,\n         1.0696e+02],\n       [ 1.0000e-02,  3.8000e-01,  1.9900e+00,  2.1038e+02,  2.2565e+02,\n         7.3320e+01],\n       [-0.0000e+00,  6.7000e-01,  2.3100e+00,  5.0030e+01,  6.2760e+01,\n         4.5120e+01],\n       [-7.0000e-02,  2.8000e-01,  2.0600e+00, -1.6474e+02, -8.9900e+01,\n         5.8240e+01],\n       [-1.8200e+00,  1.4000e-01,  1.2800e+00,  1.1925e+02, -8.8540e+01,\n         1.2853e+02],\n       [ 8.3000e-01,  1.2300e+00,  2.4500e+00, -2.1080e+01, -1.0031e+02,\n        -1.4920e+01],\n       [ 5.0000e-01, -4.4000e-01,  1.4000e+00, -1.7851e+02,  2.5740e+01,\n        -1.0030e+01],\n       [ 4.0000e-02, -3.1000e-01,  1.3500e+00, -4.4940e+01,  2.1670e+01,\n        -5.8170e+01],\n       [ 1.9000e-01,  1.1000e-01,  1.5500e+00, -2.9160e+01, -6.7000e+01,\n        -1.2950e+01],\n       [ 2.5000e-01, -7.0000e-02,  1.5900e+00, -6.7300e+01, -1.2792e+02,\n        -2.0550e+01],\n       [ 2.3000e-01, -6.0000e-02,  1.3900e+00, -9.8230e+01, -1.5847e+02,\n        -3.9890e+01],\n       [ 3.4000e-01, -1.0000e-01,  9.6000e-01, -1.0609e+02, -1.8651e+02,\n        -5.8580e+01],\n       [ 2.2000e-01,  2.0000e-01,  5.1000e-01, -1.1311e+02, -2.1341e+02,\n        -7.3910e+01],\n       [ 1.0000e-01,  2.5000e-01,  4.0000e-01, -1.3115e+02, -2.1114e+02,\n        -8.1830e+01],\n       [-1.2000e-01,  3.0000e-01,  3.8000e-01, -1.3794e+02, -1.9018e+02,\n        -9.8110e+01],\n       [-3.6000e-01,  2.8000e-01,  3.0000e-01, -1.2627e+02, -1.8649e+02,\n        -1.1435e+02],\n       [-6.1000e-01,  4.0000e-01,  1.6000e-01, -9.9350e+01, -2.2762e+02,\n        -1.1882e+02],\n       [-7.4000e-01,  5.9000e-01, -1.0000e-01, -1.0123e+02, -2.5000e+02,\n        -8.8570e+01],\n       [-6.6000e-01,  5.3000e-01, -3.4000e-01, -1.2418e+02, -2.5000e+02,\n        -6.9060e+01],\n       [-7.0000e-01,  2.4000e-01, -5.5000e-01, -9.3300e+01, -2.5000e+02,\n        -7.4940e+01],\n       [-9.0000e-01,  3.5000e-01, -6.0000e-01, -2.8730e+01, -2.5000e+02,\n        -1.0360e+02],\n       [-1.2300e+00,  5.7000e-01, -6.8000e-01, -6.4300e+00, -2.5000e+02,\n        -1.1930e+02],\n       [-1.2600e+00,  7.1000e-01, -6.7000e-01, -3.0970e+01, -2.5000e+02,\n        -1.1914e+02],\n       [-1.3100e+00,  8.2000e-01, -8.4000e-01, -7.9790e+01, -2.5000e+02,\n        -1.3533e+02],\n       [-1.6400e+00,  8.3000e-01, -9.5000e-01, -9.3610e+01, -2.5000e+02,\n        -1.5154e+02],\n       [-1.7300e+00,  7.8000e-01, -1.0200e+00, -7.2930e+01, -2.5000e+02,\n        -1.5226e+02],\n       [-1.5700e+00,  1.1000e+00, -1.1500e+00, -7.0810e+01, -2.5000e+02,\n        -1.5417e+02],\n       [-1.7400e+00,  1.5100e+00, -1.4900e+00, -1.1126e+02, -2.5000e+02,\n        -1.6974e+02],\n       [-1.8500e+00,  1.8300e+00, -1.8100e+00, -1.5255e+02, -2.5000e+02,\n        -1.9715e+02],\n       [-1.6400e+00,  1.7400e+00, -2.0000e+00, -1.2742e+02, -2.5000e+02,\n        -1.6490e+02],\n       [-1.3800e+00,  1.8000e+00, -2.1800e+00, -7.3120e+01, -2.5000e+02,\n        -1.3055e+02],\n       [-1.1600e+00,  2.1400e+00, -2.2200e+00, -5.4180e+01, -2.1140e+02,\n        -1.1552e+02]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "len(df)\n",
    "df.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.28it/s]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "start!\n",
      "(10911, 50, 6)\n",
      "(10911, 50, 6)\n",
      "(10911, 50, 6)\n",
      "(10911, 50, 6)\n",
      "(10911, 50, 6)\n",
      "(10911, 50, 6)\n",
      "(10911, 50, 6)\n",
      "ok!\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "array([[[-1.7500e+00,  1.9000e-01, -3.3000e-01,  2.2770e+01,\n          2.4999e+02,  2.4999e+02],\n        [-1.6500e+00, -1.0000e-02, -1.1000e-01,  9.0100e+01,\n          2.4999e+02,  2.4552e+02],\n        [-1.3400e+00,  4.0000e-02,  1.3000e-01,  1.2638e+02,\n          2.4999e+02,  2.2218e+02],\n        ...,\n        [-7.9000e-01,  2.4900e+00, -3.6100e+00, -9.9390e+01,\n          5.4380e+01,  2.3390e+01],\n        [-1.1200e+00,  2.1900e+00, -3.4100e+00, -4.0690e+01,\n          1.4500e+02,  9.3510e+01],\n        [-1.6200e+00,  2.2000e+00, -3.0000e+00,  1.0530e+01,\n          2.2304e+02,  1.2435e+02]],\n\n       [[-2.3000e-01,  2.5000e-01,  2.4000e-01, -1.3695e+02,\n         -2.0723e+02, -8.3020e+01],\n        [-3.9000e-01,  1.4000e-01,  1.1000e-01, -1.1826e+02,\n         -2.0531e+02, -9.0680e+01],\n        [-5.0000e-01,  8.0000e-02,  5.0000e-02, -8.7340e+01,\n         -2.1457e+02, -9.5150e+01],\n        ...,\n        [-1.8200e+00,  1.4000e-01,  1.2800e+00,  1.1925e+02,\n         -8.8540e+01,  1.2853e+02],\n        [ 8.3000e-01,  1.2300e+00,  2.4500e+00, -2.1080e+01,\n         -1.0031e+02, -1.4920e+01],\n        [ 5.0000e-01, -4.4000e-01,  1.4000e+00, -1.7851e+02,\n          2.5740e+01, -1.0030e+01]],\n\n       [[-1.9400e+00,  2.0700e+00, -2.5700e+00,  3.1700e+00,\n          2.4999e+02,  1.3746e+02],\n        [-2.2300e+00,  1.8600e+00, -2.1500e+00, -2.0940e+01,\n          2.4999e+02,  1.5142e+02],\n        [-2.5100e+00,  1.6500e+00, -1.9200e+00, -4.0050e+01,\n          2.4999e+02,  1.6670e+02],\n        ...,\n        [-1.6400e+00,  1.7400e+00, -2.0000e+00, -1.2742e+02,\n         -2.5000e+02, -1.6490e+02],\n        [-1.3800e+00,  1.8000e+00, -2.1800e+00, -7.3120e+01,\n         -2.5000e+02, -1.3055e+02],\n        [-1.1600e+00,  2.1400e+00, -2.2200e+00, -5.4180e+01,\n         -2.1140e+02, -1.1552e+02]],\n\n       ...,\n\n       [[-5.4000e-01,  1.0500e+00, -3.9000e-01,  7.0700e+00,\n          2.4999e+02, -1.6450e+02],\n        [-6.4000e-01,  1.1700e+00, -1.3000e-01, -5.1700e+01,\n          2.4999e+02, -1.4664e+02],\n        [-4.8000e-01,  9.2000e-01, -2.5000e-01, -6.7090e+01,\n          2.1218e+02, -1.0918e+02],\n        ...,\n        [-9.0000e-02,  6.6000e-01, -1.0100e+00, -5.1000e+00,\n          6.5140e+01, -3.1180e+01],\n        [-1.9000e-01,  6.9000e-01, -9.6000e-01, -3.4600e+00,\n          7.9090e+01, -3.7500e+01],\n        [-2.0000e-01,  7.1000e-01, -9.7000e-01, -1.4780e+01,\n          7.8410e+01, -4.0790e+01]],\n\n       [[-4.7000e-01,  9.2000e-01, -8.0000e-02, -4.9180e+01,\n         -1.8872e+02,  1.0934e+02],\n        [-4.6000e-01,  7.5000e-01, -1.8000e-01, -2.8190e+01,\n         -2.3927e+02,  1.2539e+02],\n        [-4.2000e-01,  6.8000e-01, -3.0000e-01,  2.4830e+01,\n         -2.5000e+02,  1.5063e+02],\n        ...,\n        [-5.4000e-01,  1.2500e+00,  2.9000e-01, -3.7810e+01,\n          1.0222e+02, -5.2090e+01],\n        [-5.0000e-01,  1.1500e+00,  2.8000e-01, -2.5120e+01,\n          4.1820e+01, -2.1690e+01],\n        [-4.6000e-01,  1.1600e+00,  2.7000e-01, -4.9100e+00,\n         -4.6700e+00,  1.1100e+00]],\n\n       [[-1.9000e-01,  6.6000e-01, -1.0100e+00, -2.8890e+01,\n          1.0533e+02, -4.6650e+01],\n        [-2.5000e-01,  6.6000e-01, -9.5000e-01, -3.9270e+01,\n          1.3735e+02, -5.5700e+01],\n        [-3.2000e-01,  6.8000e-01, -8.5000e-01, -4.5710e+01,\n          1.6821e+02, -6.5090e+01],\n        ...,\n        [-2.0000e-01,  7.1000e-01, -8.6000e-01, -6.4000e-01,\n         -1.8918e+02,  9.7920e+01],\n        [-2.1000e-01,  6.3000e-01, -8.5000e-01,  3.8100e+00,\n         -1.5829e+02,  8.2210e+01],\n        [-2.2000e-01,  5.6000e-01, -8.9000e-01,  2.3550e+01,\n         -1.3815e+02,  6.4930e+01]]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sliding window function and params\n",
    "\"\"\"\n",
    "from tqdm import tqdm\n",
    "\n",
    "csv1 = 'training_data/combined_buddhaClap.csv'\n",
    "csv2 = 'training_data/combined_crankLeft.csv'\n",
    "csv3 = 'training_data/combined_crankRight.csv'\n",
    "csv4 = 'training_data/combined_knobLeft.csv'\n",
    "csv5 = 'training_data/combined_knobRight.csv'\n",
    "csv6= 'training_data/combined_pushback.csv'\n",
    "csv7 = 'training_data/combined_swipe.csv'\n",
    "\n",
    "window = 50\n",
    "overlap = 25\n",
    "\n",
    "from skimage.util.shape import view_as_windows\n",
    "import warnings\n",
    "\n",
    "def strided_axis0(a, L, overlap=1):\n",
    "    if L==overlap:\n",
    "        raise Exception(\"Overlap arg must be smaller than length of windows\")\n",
    "    S = L - overlap\n",
    "    nd0 = ((len(a)-L)//S)+1\n",
    "    if nd0*S-S!=len(a)-L:\n",
    "        warnings.warn(\"Not all elements were covered\")\n",
    "    output = view_as_windows(a, (L,a.shape[1]), step=S)[:,0,:,:]\n",
    "    print(output.shape)\n",
    "    return output\n",
    "\n",
    "\n",
    "# total_array = np.empty((0,6))\n",
    "total_array = np.empty((0,50,6))\n",
    "csv_list = [csv1, csv2, csv3, csv4, csv5, csv6, csv7]\n",
    "print('start!')\n",
    "for csv in tqdm(csv_list):\n",
    "    df = pd.read_csv(csv)\n",
    "    window_array = strided_axis0(df.to_numpy(), 50, overlap=25)\n",
    "    # total_array += window_df.to_numpy()\n",
    "    # window_array = window_df.to_xarray().to_array()\n",
    "    total_array = np.append(total_array, window_array , axis = 0)\n",
    "print('ok!')\n",
    "total_array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(76377, 50, 6)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "total_array.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "SAVE 3D (76377, 50, 6) ARRAY TO CSV\n",
    "\"\"\"\n",
    "filename = 'window.csv'\n",
    "arr = total_array\n",
    "arrReshaped = arr.reshape(arr.shape[0], -1)\n",
    "# saving reshaped array to file.\n",
    "np.savetxt(filename, arrReshaped)\n",
    "# retrieving data from file.\n",
    "loadedArr = np.loadtxt(filename)\n",
    "# This loadedArr is a 2D array, therefore we need to convert it to the original array shape.\n",
    "# reshaping to get original matrice with original shape.\n",
    "loadedOriginal = loadedArr.reshape(loadedArr.shape[0], loadedArr.shape[1] // arr.shape[2], arr.shape[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "shape of arr:  (76377, 50, 6)\n",
      "shape of load_original_arr:  (76377, 50, 6)\n",
      "Yes, both the arrays are same\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Save into txt file\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "arr = total_array\n",
    "  \n",
    "# reshaping the array from 3D \n",
    "# matrice to 2D matrice. \n",
    "arr_reshaped = arr.reshape(arr.shape[0], -1) \n",
    "  \n",
    "# saving reshaped array to file. \n",
    "np.savetxt(\"numpy-window.txt\", arr_reshaped) \n",
    "  \n",
    "# retrieving data from file. \n",
    "loaded_arr = np.loadtxt(\"numpy-window.txt\") \n",
    "  \n",
    "# This loadedArr is a 2D array, therefore \n",
    "# we need to convert it to the original \n",
    "# array shape.reshaping to get original \n",
    "# matrice with original shape. \n",
    "load_original_arr = loaded_arr.reshape( \n",
    "    loaded_arr.shape[0], loaded_arr.shape[1] // arr.shape[2], arr.shape[2]) \n",
    "  \n",
    "# check the shapes: \n",
    "print(\"shape of arr: \", arr.shape) \n",
    "print(\"shape of load_original_arr: \", load_original_arr.shape) \n",
    "  \n",
    "# check if both arrays are same or not: \n",
    "if (load_original_arr == arr).all(): \n",
    "    print(\"Yes, both the arrays are same\") \n",
    "else: \n",
    "    print(\"No, both the arrays are not same\") "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(76377, 50, 6)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "(total_array.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load data contents\n",
    "\"\"\"\n",
    "print('start!')\n",
    "import numpy as np\n",
    "shape = (76377, 50, 6)\n",
    "loaded_arr = np.loadtxt(\"numpy-window.txt\") \n",
    "load_original_arr = loaded_arr.reshape( \n",
    "    loaded_arr.shape[0], loaded_arr.shape[1] // shape[2], shape[2]) \n",
    "load_original_arr.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create gesture class labels according to index\n",
    "1: buddha clap\n",
    "2: crank left\n",
    "3: crank right\n",
    "4: knob left\n",
    "5: knob right\n",
    "6: pushback\n",
    "7: swipe\n",
    "\"\"\"\n",
    "y_array = np.empty((0,1), int)\n",
    "for i in range(1,8):\n",
    "    label_array = np.full((10911,1), i)\n",
    "    y_array = np.append(y_array, label_array , axis = 0)\n",
    "y_array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_array = load_original_arr\n",
    "\n",
    "# y_array.shape\n",
    "x_array.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split into train-test data\n",
    "\"\"\"\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_ratio = 0.7\n",
    "class_size = 10911 ## number of samples per class\n",
    "x_train = np.empty((0,50,6))\n",
    "y_train = np.empty((0,1), int)\n",
    "x_test = np.empty((0,50,6))\n",
    "y_test = np.empty((0,1), int)\n",
    "for i in tqdm(range(7)):\n",
    "    start = i*(class_size)\n",
    "    stop =  (i+1)*(class_size)-1\n",
    "    for index, (x,y) in enumerate(zip(x_array[start:stop], y_array[start:stop])):\n",
    "        # print(index)\n",
    "        if index < train_ratio*class_size:\n",
    "            x_train = np.insert(x_train, 0, x, axis = 0)\n",
    "            y_train = np.insert(y_train, 0, y, axis = 0)\n",
    "        else:\n",
    "            x_test = np.insert(x_test, 0, x, axis = 0)\n",
    "            y_test = np.insert(y_test, 0, y, axis = 0)\n",
    "x_train\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SAVE INTO text & numpy\n",
    "\"\"\"\n",
    "## save into numpy file\n",
    "np.save('ready_data/x_train.npz', x_train)\n",
    "np.save('ready_data/y_train.npz', y_train)\n",
    "np.save('ready_data/x_test.npz', x_test)\n",
    "np.save('ready_data/y_test.npz', y_test)\n",
    "\n",
    "\n",
    "\n",
    "# reshaping the array from 3D \n",
    "# matrice to 2D matrice. \n",
    "arr_reshaped = x_train.reshape(x_train.shape[0], -1) \n",
    "arr_reshaped1 = x_test.reshape(x_test.shape[0], -1)\n",
    "arr_reshaped2 = y_train#.reshape(y_train.shape[0], -1)\n",
    "arr_reshaped3 = y_test#.reshape(y_test.shape[0], -1)\n",
    "\n",
    "# saving reshaped array to file. \n",
    "np.savetxt(\"ready_data/x_train.txt\", arr_reshaped) \n",
    "np.savetxt(\"ready_data/x_test.txt\", arr_reshaped1) \n",
    "np.savetxt(\"ready_data/y_train.txt\", arr_reshaped2) \n",
    "np.savetxt(\"ready_data/y_test.txt\", arr_reshaped3) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%arr = total_array\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-f72a3b36",
   "language": "python",
   "display_name": "PyCharm (grits)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}